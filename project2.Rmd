---
title: "Shape of the tuning curve"
author: "Rasmus Munter"
date: "May 11, 2018"
output:
    pdf_document:
        fig_caption: true
        fig_height: 3
        fig_width: 5.5
header-includes:
    - \usepackage{float}
    - \usepackage{caption}
---
\captionsetup{width=5.5in}

```{r 'load project1 data', include=FALSE}
library(knitr)
library(ggpubr)
knit_child('project1.Rmd', options=list(include=FALSE))
theme_set(theme_bw())
```

There are multiple models for how headcells are formed and obtain their tuning. Two of these are the continous attractor and learning model. The former predicts that the tuning curve for a HD cell should follow a cosine curve while the learning model predicts a gaussian tuning curve. To test these hypotheses the two curves were fit to the tuning curves of the 10 HD cells found in the previous project. The gaussian curve is defined as 

$$
f(x) = A + B\cdot\text{exp}\bigg[-\Bigg(\frac{x-P}{C}\bigg)^2\Bigg]
$$

while the cosine curve is defined as
\begin{align*}
    f(x) = 
    \begin{cases}
        A + B \cdot (1 + cos(C\cdot(x-P))) \quad &if\quad |C(x-P)|<\pi \\
        A \quad &else
    \end{cases}
\end{align*}

In our case, $x$ is the binned head angle and $f(x)$ is the firing rate. The capatilized letters are uknown parameters that are tuned by minimizng the root mean square error between the model and the calculate tuning curve.

```{r echo=FALSE, include=TRUE, fig.cap=caption}
# Cortex cell model

source("./util/problem2.R")
cortex_cells = addGaussianEstimate(cortex_cells)
cortex_cells = addCosineEstimate(cortex_cells)
p1 = ggplot(data=cortex_cells) + geom_line(aes(x=angle_bins, y=firing_rate, color='true', group=cellname), alpha=0.8, size=1.2) +
    geom_line(aes(x=angle_bins, y=gaussian_estimate, group=cellname, color='gaussian'), alpha=0.8, size=1.2) +
    geom_line(aes(x=angle_bins, y=cosine_estimate, group=cellname, color='cosine'), alpha=0.8, size=1.2) +
    facet_wrap(~cellname, ncol=3, scale='free_y') +
    scale_color_brewer(breaks=c('true','gaussian','cosine'), palette='Set2') +
    theme(axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),
          axis.text.x = element_blank(), axis.text.y = element_blank(),
          axis.title.x=element_blank(), axis.title.y=element_blank())

## Thalamus cell model

thalamus_cells = addGaussianEstimate(thalamus_cells)
thalamus_cells = addCosineEstimate(thalamus_cells)
p2 = ggplot(data=thalamus_cells) + geom_line(aes(x=angle_bins, y=firing_rate, group=cellname, color='true'), alpha=1, size=2) +
    geom_line(aes(x=angle_bins, y=gaussian_estimate, 
                  group=cellname, color='gaussian'), alpha=0.8, size=1) +
    geom_line(aes(x=angle_bins, y=cosine_estimate, 
                  group=cellname, color='cosine'), alpha=0.8, size=1) +
    facet_wrap(~cellname, ncol=3, scale='free_y') +
    scale_color_brewer(breaks=c('true','gaussian','cosine'), palette='Set2') + 
    theme(axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),
          axis.text.x = element_blank(), axis.text.y = element_blank(),
          axis.title.x=element_blank(), axis.title.y=element_blank())

p = ggarrange(p1,p2,nrow=1,ncol=2, labels="AUTO", common.legend = TRUE)
annotate_figure(p,
                bottom = text_grob("Angle (degrees)"),
                left = text_grob("Firing rate (Spikes/s)", rot = 90)
                )
caption="\\label{models}\\textbf{Models overlaying estimated tuning curve.} A gaussian and cosine curve were fit to the tuning curves by optimizing their tuning parameters to minimize root mean square error. A: Curves for cortex HD cells, B: Curves for thalamus HD cells"
```

Both models managed to fit a curve relatively well compared to the actual tuning curve. To compare the two models the RMSE of each model was plotted in figure \ref{modelRMSE}.

```{r echo=FALSE, include=TRUE, fig.cap=caption}
## RMSE plot

cortex_cells$type = 'cortex'
thalamus_cells$type = 'thalamus'
all_cells = rbind(cortex_cells, thalamus_cells)
ggplot(data=all_cells, aes(x=gaussian_RMSE, y=cosine_RMSE)) +
    geom_point() +  geom_smooth(method='lm',formula=y~x)

caption="\\label{modelRMSE}\\textbf{RMSE comparison between models:} The line of best fit indicates that the gaussian curve is a better fit."
```

As the gradient of the line of best fit is less than 1 the plot above suggests that the gaussian curve and thus the learning model is the best explanation for head direction cells. However since this analysis is done on only 10 cells and the difference in RMSE is relatively small, these results are not conclusive.